{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f158ee02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f158ee02",
        "outputId": "917897f1-fd0b-42bf-bba5-c6a3f97cec23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "77d4616b",
      "metadata": {
        "id": "77d4616b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, MaxAbsScaler\n",
        "\n",
        "# ─── configuration ───────────────────────────────────────────────────────────\n",
        "root           = Path(\".\")\n",
        "forecast_dir   = root / \"bmrs_csv_filled\"\n",
        "df_path        = root / forecast_dir / \"df_all.csv\"\n",
        "mask_dir       = root / \"bmrs_csv_masks\"\n",
        "\n",
        "date_start     = \"2021-07-01\"\n",
        "date_end       = \"2025-06-30\"\n",
        "train_end_date = \"2025-03-01\"\n",
        "val_end_date   = \"2025-05-01\"\n",
        "\n",
        "horizon        = 48\n",
        "use_time_feat  = False   # whether to add trig-based time features\n",
        "\n",
        "# ─── sanity checks & seeding ─────────────────────────────────────────────────\n",
        "assert df_path.exists(), f\"{df_path} not found\"\n",
        "for d in (forecast_dir, mask_dir):\n",
        "    assert d.exists(), f\"{d} not found\"\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b6933fe5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6933fe5",
        "outputId": "e7a57324-bed5-4446-fb2c-541b6e8de7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[debug] loaded df rows = 70126\n",
            "                     month_idx  weekday_idx  sp_idx  dtype_idx\n",
            "startTime                                                     \n",
            "2021-07-01 00:00:00          6            3       2          0\n",
            "2021-07-01 00:30:00          6            3       3          0\n",
            "2021-07-01 01:00:00          6            3       4          0\n",
            "2021-07-01 01:30:00          6            3       5          0\n",
            "2021-07-01 02:00:00          6            3       6          0\n",
            "[debug] DEMAND_FORECASTS: 70126 rows reindexed\n",
            "[debug] DEMAND_FORECASTS: full horizon loaded\n",
            "[debug] WIND_FORECASTS: 70126 rows reindexed\n",
            "[debug] WIND_FORECASTS: full horizon loaded\n",
            "[debug] DRM_FORECASTS: 70126 rows reindexed\n",
            "[debug] DRM_FORECASTS: full horizon loaded\n",
            "[debug] x_fut shape = (70126, 48, 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bc/9771s35x1x92qwjdzftm3svc0000gn/T/ipykernel_97099/3808848117.py:28: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  pd.read_csv(path, index_col=\"startTime\", parse_dates=True)\n"
          ]
        }
      ],
      "source": [
        "df = (\n",
        "    pd.read_csv(df_path, index_col=\"startTime\", parse_dates=True)\n",
        "      .loc[date_start:date_end]\n",
        ")\n",
        "print(f\"[debug] loaded df rows = {len(df)}\")\n",
        "\n",
        "# drop any forecast/actual cols\n",
        "to_drop = [c for c in df.columns if \"forecast\" in c.lower() or \"actual\" in c.lower()]\n",
        "df.drop(columns=to_drop, errors=\"ignore\", inplace=True)\n",
        "\n",
        "# embed time features\n",
        "df[\"month_idx\"]   = df.index.month - 1\n",
        "df[\"weekday_idx\"] = df.index.dayofweek\n",
        "if \"settlement period\" in (c.lower() for c in df.columns):\n",
        "    df[\"sp_idx\"] = df.pop(\"Settlement Period\").astype(int) - 1\n",
        "else:\n",
        "    df[\"sp_idx\"] = 0\n",
        "    print(\"[warn] 'settlement period' not found; sp_idx set to 0\")\n",
        "df[\"dtype_idx\"]   = (df.index.dayofweek >= 5).astype(int)\n",
        "\n",
        "print(df[[\"month_idx\",\"weekday_idx\",\"sp_idx\",\"dtype_idx\"]].head())\n",
        "\n",
        "def load_forecast_matrix(name, prefix, idx, horizon):\n",
        "    path = forecast_dir / f\"{name}.csv\"\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"{path} not found\")\n",
        "    fdf = (\n",
        "        pd.read_csv(path, index_col=\"startTime\", parse_dates=True)\n",
        "          .loc[date_start:date_end]\n",
        "          .reindex(idx)\n",
        "    )\n",
        "    print(f\"[debug] {name}: {len(fdf)} rows reindexed\")\n",
        "    cols    = [f\"{prefix}_f{i}\" for i in range(1, horizon+1)]\n",
        "    present = [c for c in cols if c in fdf.columns]\n",
        "    mat     = fdf[present].fillna(0).to_numpy()\n",
        "    if mat.shape[1] < horizon:\n",
        "        pad = np.zeros((len(mat), horizon - mat.shape[1]), dtype=mat.dtype)\n",
        "        mat = np.hstack([mat, pad])\n",
        "        print(f\"[debug] {name}: padded from {len(present)}→{horizon}\")\n",
        "    else:\n",
        "        print(f\"[debug] {name}: full horizon loaded\")\n",
        "    return mat\n",
        "\n",
        "idx        = df.index\n",
        "demand_mat = load_forecast_matrix(\"DEMAND_FORECASTS\", \"demand\", idx, horizon)\n",
        "wind_mat   = load_forecast_matrix(\"WIND_FORECASTS\",   \"wind\",   idx, horizon)\n",
        "drm_mat    = load_forecast_matrix(\"DRM_FORECASTS\",    \"drm\",    idx, horizon)\n",
        "x_fut      = np.stack([demand_mat, wind_mat, drm_mat], axis=2)\n",
        "assert x_fut.shape[0] == len(df)\n",
        "print(f\"[debug] x_fut shape = {x_fut.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "439e5f6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "439e5f6f",
        "outputId": "9b467681-095a-4637-c668-b1fff37956fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train → x_hist (64272, 10), x_cal (64272, 4), y (64272,), x_fut (64272, 48, 3)\n",
            "val   → x_hist (2928, 10), x_cal (2928, 4), y (2928,), x_fut (2928, 48, 3)\n",
            "test  → x_hist (2926, 10), x_cal (2926, 4), y (2926,), x_fut (2926, 48, 3)\n"
          ]
        }
      ],
      "source": [
        "target_col = \"Imbalance Price\"\n",
        "assert target_col in df.columns, f\"missing target: {target_col}\"\n",
        "\n",
        "masks = {\n",
        "    \"train\": df.index < train_end_date,\n",
        "    \"val\"  : (df.index >= train_end_date) & (df.index < val_end_date),\n",
        "    \"test\" : df.index >= val_end_date,\n",
        "}\n",
        "\n",
        "cal_cols  = [\"month_idx\",\"weekday_idx\",\"sp_idx\",\"dtype_idx\"]\n",
        "hist_cols = [c for c in df.columns if c not in cal_cols]\n",
        "\n",
        "splits = {}\n",
        "for split, mask in masks.items():\n",
        "    sub = df.loc[mask]\n",
        "    splits[split] = {\n",
        "        \"x_hist\": sub[hist_cols].to_numpy(),\n",
        "        \"x_cal\" : sub[cal_cols].to_numpy(),\n",
        "        \"y\"     : sub[target_col].to_numpy(),\n",
        "        \"x_fut\" : x_fut[mask],\n",
        "    }\n",
        "    print(\n",
        "        f\"{split:5s} → \"\n",
        "        f\"x_hist {splits[split]['x_hist'].shape}, \"\n",
        "        f\"x_cal {splits[split]['x_cal'].shape}, \"\n",
        "        f\"y {splits[split]['y'].shape}, \"\n",
        "        f\"x_fut {splits[split]['x_fut'].shape}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bce6e443",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bce6e443",
        "outputId": "e0d5eb16-2c97-475a-f677-d54390cd1058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "configs → seq=48, feed=48, fut=4; batch=144, lr=0.0001, epochs=200\n"
          ]
        }
      ],
      "source": [
        "# Cell 3 ─── dataset & model class definitions (with inline comments) ──────\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from src.models.factory import MODEL_FACTORY\n",
        "from src.datasets.factory import DATASET_FACTORY\n",
        "\n",
        "transformer_factory = {\n",
        "    \"MinMax\":   MinMaxScaler,\n",
        "    \"Robust\":   RobustScaler,\n",
        "    \"Standard\": StandardScaler,\n",
        "    \"MaxAbs\":   MaxAbsScaler,\n",
        "}\n",
        "\n",
        "loss_factory = {\n",
        "    \"MAE\":   nn.L1Loss,\n",
        "    \"MSE\":   nn.MSELoss,\n",
        "    \"Huber\": nn.SmoothL1Loss,\n",
        "}\n",
        "\n",
        "# model & sequence configuration\n",
        "seq_len   = 48   # look-back window\n",
        "feed_len  = 48   # known-future window\n",
        "fut_len   = 4   # forecast horizon\n",
        "\n",
        "# network widths & depths\n",
        "lstm_hidden = 64\n",
        "dec_hidden  = 64\n",
        "attn_dim    = 48\n",
        "num_layers  = 1\n",
        "dropout     = 0.0\n",
        "\n",
        "# training settings\n",
        "batch_size = 144\n",
        "lr         = 1e-3\n",
        "patience   = 20\n",
        "max_epochs = 200\n",
        "\n",
        "# scaler & loss choices (must match factory keys)\n",
        "scaler_used = \"MaxAbs\"\n",
        "model_used  = \"BiAttnPointForecaster\"\n",
        "loss_used   = \"MSE\"\n",
        "beta        = 0.01   # only for Huber loss\n",
        "notes       = None\n",
        "\n",
        "print(f\"configs → seq={seq_len}, feed={feed_len}, fut={fut_len}; \"\n",
        "      f\"batch={batch_size}, lr={lr}, epochs={max_epochs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7d84e7ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d84e7ee",
        "outputId": "68e562c6-7f36-48c0-a846-64a29df797b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[info] saving model to: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_nl1_bs144_lr.0001_me200_p20_MaxAbs_Huber_v1\n"
          ]
        }
      ],
      "source": [
        "# ─── metadata & model directory ─────────────────────────────────────────────\n",
        "from pathlib import Path\n",
        "\n",
        "# metadata dict\n",
        "md = {\n",
        "    \"model\":        model_used,\n",
        "    \"seq_len\":      seq_len,\n",
        "    \"feed_len\":     feed_len,\n",
        "    \"horizon\":      fut_len,\n",
        "    \"lstm_hidden\":  lstm_hidden,\n",
        "    \"dec_hidden\":   dec_hidden,\n",
        "    \"num_layers\":   num_layers,\n",
        "    \"batch_size\":   batch_size,\n",
        "    \"learning_rate\":lr,\n",
        "    \"max_epochs\":   max_epochs,\n",
        "    \"patience\":     patience,\n",
        "    \"scaler\":       scaler_used,\n",
        "    \"loss\":         loss_used,\n",
        "    **({\"notes\": notes} if notes else {}),\n",
        "}\n",
        "\n",
        "# helper to abbreviate keys\n",
        "initials = lambda s: \"\".join(w[0] for w in s.split(\"_\"))\n",
        "\n",
        "# build tag parts\n",
        "parts = []\n",
        "for k, v in md.items():\n",
        "    sv = str(v)\n",
        "    if isinstance(v, float) and sv.startswith(\"0.\"):\n",
        "        sv = sv.replace(\"0.\", \".\")\n",
        "    part = sv if k in {\"model\",\"scaler\",\"loss\",\"notes\"} else f\"{initials(k)}{sv}\"\n",
        "    parts.append(part)\n",
        "\n",
        "# combine into tag\n",
        "tag = \"_\".join(parts)\n",
        "\n",
        "# determine candidate path, bumping version if needed\n",
        "models_root = Path(\"saved_runs\")\n",
        "candidate   = models_root / tag\n",
        "version     = 0\n",
        "while candidate.exists():\n",
        "    version    += 1\n",
        "    candidate   = models_root / f\"{tag}_v{version}\"\n",
        "\n",
        "print(f\"[info] saving model to: {candidate}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4745bbb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4745bbb1",
        "outputId": "cfaa9b79-1c5b-43cf-a032-0be64443ccf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_hist_feats: 10\n",
            "num_fut_feats: 3\n",
            "time_feat_dim: 15\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m out  \u001b[38;5;241m=\u001b[39m model(x_h, x_f, mi, wi, si, di)\n\u001b[1;32m    137\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, y_t)\n\u001b[0;32m--> 138\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    140\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/_tensor.py:624\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    616\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    617\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    623\u001b[0m     )\n\u001b[0;32m--> 624\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ─── train/val/test loop + early stopping ─────────────────────────────────\n",
        "import os\n",
        "import json\n",
        "import copy\n",
        "import joblib\n",
        "import sys\n",
        "import platform\n",
        "from datetime import datetime, timezone\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from src.datasets.datasets import MultiFeedDataset\n",
        "\n",
        "# create output directory\n",
        "base_dir = candidate  # candidate is a pathlib.Path\n",
        "base_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"→ saving run in: {base_dir}\")\n",
        "\n",
        "# rebuild train/val/test df slices for metadata\n",
        "df_train = df.loc[masks[\"train\"]]\n",
        "df_val   = df.loc[masks[\"val\"]]\n",
        "df_test  = df.loc[masks[\"test\"]]\n",
        "\n",
        "# 1) scale train/val/test\n",
        "\n",
        "# a) history features\n",
        "scaler_x = transformer_factory[scaler_used]()\n",
        "x_train_hist_scaled = scaler_x.fit_transform(splits[\"train\"][\"x_hist\"])\n",
        "x_val_hist_scaled   = scaler_x.transform(splits[\"val\"][\"x_hist\"])\n",
        "x_test_hist_scaled  = scaler_x.transform(splits[\"test\"][\"x_hist\"])\n",
        "\n",
        "# b) future features\n",
        "n_fut_feats = splits[\"train\"][\"x_fut\"].shape[2]\n",
        "scaler_f    = transformer_factory[scaler_used]()\n",
        "flat_f_train = splits[\"train\"][\"x_fut\"].reshape(-1, n_fut_feats)\n",
        "flat_f_train = scaler_f.fit_transform(flat_f_train)\n",
        "x_fut_train_scaled = flat_f_train.reshape(splits[\"train\"][\"x_fut\"].shape)\n",
        "\n",
        "flat_f_val   = splits[\"val\"][\"x_fut\"].reshape(-1, n_fut_feats)\n",
        "flat_f_val   = scaler_f.transform(flat_f_val)\n",
        "x_fut_val_scaled = flat_f_val.reshape(splits[\"val\"][\"x_fut\"].shape)\n",
        "\n",
        "flat_f_test  = splits[\"test\"][\"x_fut\"].reshape(-1, n_fut_feats)\n",
        "flat_f_test  = scaler_f.transform(flat_f_test)\n",
        "x_fut_test_scaled = flat_f_test.reshape(splits[\"test\"][\"x_fut\"].shape)\n",
        "\n",
        "# c) targets\n",
        "scaler_y       = transformer_factory[scaler_used]()\n",
        "y_train_scaled = scaler_y.fit_transform(splits[\"train\"][\"y\"].reshape(-1,1)).flatten()\n",
        "y_val_scaled   = scaler_y.transform(splits[\"val\"][\"y\"].reshape(-1,1)).flatten()\n",
        "y_test_scaled  = scaler_y.transform(splits[\"test\"][\"y\"].reshape(-1,1)).flatten()\n",
        "\n",
        "# 2) build dataloaders\n",
        "pin_memory = (device.type == \"cuda\")\n",
        "\n",
        "def to_tensor(x, dtype):\n",
        "    return torch.tensor(x, dtype=dtype)\n",
        "\n",
        "train_ds = MultiFeedDataset(\n",
        "    hist        = to_tensor(x_train_hist_scaled, torch.float32),\n",
        "    full_fut    = to_tensor(x_fut_train_scaled,    torch.float32),\n",
        "    y           = to_tensor(y_train_scaled,        torch.float32),\n",
        "    month_idx   = to_tensor(splits[\"train\"][\"x_cal\"][:,0], torch.long),\n",
        "    weekday_idx = to_tensor(splits[\"train\"][\"x_cal\"][:,1], torch.long),\n",
        "    sp_idx      = to_tensor(splits[\"train\"][\"x_cal\"][:,2], torch.long),\n",
        "    dtype_idx   = to_tensor(splits[\"train\"][\"x_cal\"][:,3], torch.long),\n",
        "    seq_len     = seq_len,\n",
        "    feed_len    = feed_len,\n",
        "    fut_len     = fut_len\n",
        ")\n",
        "val_ds = MultiFeedDataset(\n",
        "    hist        = to_tensor(x_val_hist_scaled,   torch.float32),\n",
        "    full_fut    = to_tensor(x_fut_val_scaled,    torch.float32),\n",
        "    y           = to_tensor(y_val_scaled,        torch.float32),\n",
        "    month_idx   = to_tensor(splits[\"val\"][\"x_cal\"][:,0], torch.long),\n",
        "    weekday_idx = to_tensor(splits[\"val\"][\"x_cal\"][:,1], torch.long),\n",
        "    sp_idx      = to_tensor(splits[\"val\"][\"x_cal\"][:,2], torch.long),\n",
        "    dtype_idx   = to_tensor(splits[\"val\"][\"x_cal\"][:,3], torch.long),\n",
        "    seq_len     = seq_len,\n",
        "    feed_len    = feed_len,\n",
        "    fut_len     = fut_len\n",
        ")\n",
        "test_ds = MultiFeedDataset(\n",
        "    hist        = to_tensor(x_test_hist_scaled,  torch.float32),\n",
        "    full_fut    = to_tensor(x_fut_test_scaled,   torch.float32),\n",
        "    y           = to_tensor(y_test_scaled,       torch.float32),\n",
        "    month_idx   = to_tensor(splits[\"test\"][\"x_cal\"][:,0], torch.long),\n",
        "    weekday_idx = to_tensor(splits[\"test\"][\"x_cal\"][:,1], torch.long),\n",
        "    sp_idx      = to_tensor(splits[\"test\"][\"x_cal\"][:,2], torch.long),\n",
        "    dtype_idx   = to_tensor(splits[\"test\"][\"x_cal\"][:,3], torch.long),\n",
        "    seq_len     = seq_len,\n",
        "    feed_len    = feed_len,\n",
        "    fut_len     = fut_len\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  pin_memory=pin_memory)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
        "\n",
        "# 3) instantiate model, optimizer, criterion\n",
        "time_feat_dim = 4 + 3 + 6 + 2\n",
        "model = MODEL_FACTORY[model_used](\n",
        "    num_hist_feats = x_train_hist_scaled.shape[1],\n",
        "    num_fut_feats  = n_fut_feats,\n",
        "    time_feat_dim  = time_feat_dim,\n",
        "    lstm_hidden    = lstm_hidden,\n",
        "    dec_hidden     = dec_hidden,\n",
        "    attn_dim       = attn_dim,\n",
        "    hist_len       = seq_len,\n",
        "    feed_len       = feed_len,\n",
        "    fut_len        = fut_len\n",
        ").to(device)\n",
        "\n",
        "print(f\"num_hist_feats: {x_train_hist_scaled.shape[1]}\")\n",
        "print(f\"num_fut_feats: {n_fut_feats}\")\n",
        "print(f\"time_feat_dim: {time_feat_dim}\")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = (\n",
        "    loss_factory[loss_used](beta=beta)\n",
        "    if loss_used == \"huber\"\n",
        "    else loss_factory[loss_used]()\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-7\n",
        ")\n",
        "last_lrs = scheduler.get_last_lr()\n",
        "\n",
        "# 4) train w/ early stopping on val\n",
        "best_val, epochs_no_improve, best_ckpt = float('inf'), 0, None\n",
        "\n",
        "for epoch in range(1, max_epochs+1):\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "    for x_h, x_f, y_t, mi, wi, si, di in train_loader:\n",
        "        x_h, x_f, y_t = x_h.to(device), x_f.to(device), y_t.to(device)\n",
        "        mi, wi, si, di = mi.to(device), wi.to(device), si.to(device), di.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out  = model(x_h, x_f, mi, wi, si, di)\n",
        "        loss = criterion(out, y_t)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "    train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x_h, x_f, y_t, mi, wi, si, di in val_loader:\n",
        "            x_h, x_f, y_t = x_h.to(device), x_f.to(device), y_t.to(device)\n",
        "            mi, wi, si, di = mi.to(device), wi.to(device), si.to(device), di.to(device)\n",
        "            out = model(x_h, x_f, mi, wi, si, di)\n",
        "            total_val_loss += criterion(out, y_t).item()\n",
        "    val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    new_lr = scheduler.get_last_lr()[0]\n",
        "    if new_lr != last_lrs[0]:\n",
        "        print(f\"→ lr reduced from {last_lrs[0]:.2e} to {new_lr:.2e}\")\n",
        "    last_lrs = scheduler.get_last_lr()\n",
        "\n",
        "    print(f\"[epoch {epoch:03d}] train={train_loss:.5f} val={val_loss:.5f}\")\n",
        "    if val_loss < best_val:\n",
        "        best_val, epochs_no_improve = val_loss, 0\n",
        "        best_ckpt = {\n",
        "            \"model\":     copy.deepcopy(model.state_dict()),\n",
        "            \"optimizer\": copy.deepcopy(optimizer.state_dict())\n",
        "        }\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"→ early stopping after {epoch} epochs\")\n",
        "            break\n",
        "\n",
        "# restore best checkpoint\n",
        "model.load_state_dict(best_ckpt[\"model\"])\n",
        "optimizer.load_state_dict(best_ckpt[\"optimizer\"])\n",
        "\n",
        "# 5) inference on test\n",
        "model.eval()\n",
        "preds_all, trues_all = [], []\n",
        "with torch.no_grad():\n",
        "    for x_h, x_f, y_t, mi, wi, si, di in test_loader:\n",
        "        x_h, x_f = x_h.to(device), x_f.to(device)\n",
        "        mi, wi, si, di = mi.to(device), wi.to(device), si.to(device), di.to(device)\n",
        "        out = model(x_h, x_f, mi, wi, si, di)\n",
        "        preds_all.append(out.cpu().numpy())\n",
        "        trues_all.append(y_t.numpy())\n",
        "\n",
        "preds_all = np.concatenate(preds_all, axis=0)\n",
        "trues_all = np.concatenate(trues_all, axis=0)\n",
        "preds     = scaler_y.inverse_transform(preds_all.reshape(-1,1)).flatten()\n",
        "trues     = scaler_y.inverse_transform(trues_all.reshape(-1,1)).flatten()\n",
        "errors    = trues - preds\n",
        "\n",
        "mae   = mean_absolute_error(trues, preds)\n",
        "rmse  = np.sqrt(mean_squared_error(trues, preds))\n",
        "smape = np.mean(2.0 * np.abs(errors) / (np.abs(trues) + np.abs(preds) + 1e-8)) * 100\n",
        "huber_vals = np.where(np.abs(errors) <= beta,\n",
        "                      0.5 * errors**2 / beta,\n",
        "                      np.abs(errors) - 0.5 * beta)\n",
        "huber = huber_vals.mean()\n",
        "\n",
        "print(f\"\\ntest → mae={mae:.4f}, rmse={rmse:.4f}, smape={smape:.4f}%, huber={huber:.4f}\")\n",
        "\n",
        "# 6) build metadata & save\n",
        "class NpTorchJSONEncoder(json.JSONEncoder):\n",
        "    def default(self, o):\n",
        "        if isinstance(o, np.generic):   return o.item()\n",
        "        if isinstance(o, np.ndarray):   return o.tolist()\n",
        "        if isinstance(o, torch.Tensor): return o.detach().cpu().tolist()\n",
        "        if isinstance(o, torch.device): return str(o)\n",
        "        if isinstance(o, datetime):     return o.isoformat()\n",
        "        return super().default(o)\n",
        "\n",
        "env_meta = {\n",
        "    \"seed_torch\":          torch.initial_seed(),\n",
        "    \"seed_numpy\":          np.random.get_state()[1][0],\n",
        "    \"seed_python\":         random.getstate()[1][0],\n",
        "    \"cudnn_deterministic\": getattr(torch.backends.cudnn, \"deterministic\", None),\n",
        "    \"cudnn_benchmark\":     getattr(torch.backends.cudnn, \"benchmark\", None),\n",
        "    \"torch_version\":       torch.__version__,\n",
        "    \"python_version\":      platform.python_version(),\n",
        "    \"run_timestamp\":       datetime.now(timezone.utc).isoformat()\n",
        "}\n",
        "\n",
        "data_meta = {\n",
        "    \"start\":     df_train.index.min().strftime(\"%Y-%m-%d\"),\n",
        "    \"train_end\": train_end_date,\n",
        "    \"val_end\":   val_end_date,\n",
        "    \"end\":       df_test.index.max().strftime(\"%Y-%m-%d\"),\n",
        "    \"n_train\":   len(train_loader.dataset),\n",
        "    \"n_val\":     len(val_loader.dataset),\n",
        "    \"n_test\":    len(test_loader.dataset)\n",
        "}\n",
        "\n",
        "feat_meta = {\n",
        "    \"hist_feats\": {\n",
        "        \"cols\": hist_cols,\n",
        "        \"n\": x_train_hist_scaled.shape[1]\n",
        "    },\n",
        "    \"time_feats\": {\n",
        "        \"cols\": cal_cols,\n",
        "        \"n\": time_feat_dim,\n",
        "    },\n",
        "    \"fut_feats\": {\n",
        "        \"prefixes\": [\"demand\", \"wind\", \"drm\"],  # update this to match your data\n",
        "        \"n\": n_fut_feats,\n",
        "        \"feed_len\": feed_len,\n",
        "        \"fut_len\": fut_len\n",
        "    },\n",
        "    \"total_feats\": len(hist_cols) + len(cal_cols) + n_fut_feats\n",
        "}\n",
        "\n",
        "loader_meta = {\n",
        "    \"batch_size\":  batch_size,\n",
        "    \"shuffle\":     {\"train\": True, \"val\": False, \"test\": False},\n",
        "    \"num_workers\": os.cpu_count() or 1,\n",
        "    \"pin_memory\":  pin_memory,\n",
        "    \"device\":      str(device),\n",
        "}\n",
        "\n",
        "hyperparams_meta = {\n",
        "    \"model\":         model_used,\n",
        "    \"seq_len\":       seq_len,\n",
        "    \"feed_len\":      feed_len,\n",
        "    \"horizon\":       fut_len,\n",
        "    \"lstm_hidden\":   lstm_hidden,\n",
        "    \"dec_hidden\":    dec_hidden,\n",
        "    \"attn_dim\":      attn_dim,\n",
        "    \"num_layers\":    num_layers,\n",
        "    \"batch_size\":    batch_size,\n",
        "    \"learning_rate\": lr,\n",
        "    \"scaler\":        scaler_used,\n",
        "    \"loss\":          loss_used,\n",
        "    **({\"beta\": beta} if loss_used == \"huber\" else {})\n",
        "}\n",
        "\n",
        "optim_meta = {\n",
        "    \"type\": optimizer.__class__.__name__,\n",
        "    \"lr\":   optimizer.defaults.get(\"lr\"),\n",
        "    **{k: optimizer.defaults[k]\n",
        "       for k in (\"betas\",\"eps\",\"weight_decay\")\n",
        "       if k in optimizer.defaults}\n",
        "}\n",
        "\n",
        "sched_meta = {\n",
        "    \"type\":     scheduler.__class__.__name__,\n",
        "    \"mode\":     getattr(scheduler, \"mode\", None),\n",
        "    \"factor\":   getattr(scheduler, \"factor\", None),\n",
        "    \"patience\": getattr(scheduler, \"patience\", None),\n",
        "    \"min_lr\":   (scheduler.min_lrs[0]\n",
        "                 if hasattr(scheduler, \"min_lrs\")\n",
        "                 else getattr(scheduler, \"eta_min\", None)),\n",
        "    \"last_lr\":  scheduler.get_last_lr()\n",
        "}\n",
        "\n",
        "earlystop_meta = {\n",
        "    \"max_epochs\": max_epochs,\n",
        "    \"patience\":  patience,\n",
        "    \"final_epoch\": epoch,\n",
        "    \"best_epoch\": epoch - epochs_no_improve\n",
        "}\n",
        "\n",
        "metrics_meta = {\n",
        "    \"mae\":   float(mae),\n",
        "    \"rmse\":  float(rmse),\n",
        "    \"smape\": float(smape),\n",
        "    \"huber\": float(huber)\n",
        "}\n",
        "\n",
        "\n",
        "# save model & scalers\n",
        "torch.save({\n",
        "    \"model_state_dict\":     model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    \"scheduler_state_dict\": scheduler.state_dict()\n",
        "}, base_dir / \"torch_model.pt\")\n",
        "\n",
        "joblib.dump({\n",
        "    \"scaler_x\": scaler_x,\n",
        "    \"scaler_f\": scaler_f,\n",
        "    \"scaler_y\": scaler_y\n",
        "}, str(base_dir / \"scalers.joblib\"))\n",
        "\n",
        "with open(base_dir / \"test_summary.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"environment\":  env_meta,\n",
        "        \"data\":         data_meta,\n",
        "        \"features\":     feat_meta,\n",
        "        \"dataloader\":   loader_meta,\n",
        "        \"hyperparams\":  hyperparams_meta,\n",
        "        \"optimizer\":    optim_meta,\n",
        "        \"scheduler\":    sched_meta,\n",
        "        \"early_stop\":   earlystop_meta,\n",
        "        \"metrics\":      metrics_meta\n",
        "    }, f, indent=2, cls=NpTorchJSONEncoder)\n",
        "\n",
        "print(f\"✅ saved all outputs to {base_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7518b056",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: mps\n",
            "[debug] loaded df rows = 70126\n",
            "                     month_idx  weekday_idx  sp_idx  dtype_idx\n",
            "startTime                                                     \n",
            "2021-07-01 00:00:00          6            3       2          0\n",
            "2021-07-01 00:30:00          6            3       3          0\n",
            "2021-07-01 01:00:00          6            3       4          0\n",
            "2021-07-01 01:30:00          6            3       5          0\n",
            "2021-07-01 02:00:00          6            3       6          0\n",
            "[debug] DEMAND_FORECASTS: 70126 rows reindexed\n",
            "[debug] DEMAND_FORECASTS: full horizon loaded\n",
            "[debug] WIND_FORECASTS: 70126 rows reindexed\n",
            "[debug] WIND_FORECASTS: full horizon loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bc/9771s35x1x92qwjdzftm3svc0000gn/T/ipykernel_32131/638442588.py:81: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  pd.read_csv(path, index_col=\"startTime\", parse_dates=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[debug] DRM_FORECASTS: 70126 rows reindexed\n",
            "[debug] DRM_FORECASTS: full horizon loaded\n",
            "[debug] x_fut shape = (70126, 48, 3)\n",
            "train → x_hist (64272, 10), x_cal (64272, 4), y (64272,), x_fut (64272, 48, 3)\n",
            "val   → x_hist (2928, 10), x_cal (2928, 4), y (2928,), x_fut (2928, 48, 3)\n",
            "test  → x_hist (2926, 10), x_cal (2926, 4), y (2926,), x_fut (2926, 48, 3)\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0002\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0001\n",
            "[046] train=0.0003 val=0.0001\n",
            "[047] train=0.0003 val=0.0001\n",
            "[048] train=0.0003 val=0.0001\n",
            "[049] train=0.0003 val=0.0001\n",
            "[050] train=0.0003 val=0.0001\n",
            "[051] train=0.0003 val=0.0001\n",
            "[052] train=0.0003 val=0.0001\n",
            "[053] train=0.0003 val=0.0001\n",
            "[054] train=0.0003 val=0.0001\n",
            "[055] train=0.0003 val=0.0001\n",
            "[056] train=0.0003 val=0.0001\n",
            "[057] train=0.0003 val=0.0001\n",
            "[058] train=0.0003 val=0.0001\n",
            "[059] train=0.0003 val=0.0001\n",
            "[060] train=0.0003 val=0.0001\n",
            "[061] train=0.0003 val=0.0001\n",
            "[062] train=0.0003 val=0.0001\n",
            "[063] train=0.0003 val=0.0001\n",
            "[064] train=0.0003 val=0.0001\n",
            "[065] train=0.0003 val=0.0001\n",
            "[066] train=0.0003 val=0.0001\n",
            "[067] train=0.0003 val=0.0001\n",
            "[068] train=0.0003 val=0.0001\n",
            "[069] train=0.0003 val=0.0001\n",
            "[070] train=0.0003 val=0.0001\n",
            "[071] train=0.0002 val=0.0001\n",
            "[072] train=0.0002 val=0.0000\n",
            "[073] train=0.0002 val=0.0001\n",
            "[074] train=0.0002 val=0.0000\n",
            "[075] train=0.0002 val=0.0001\n",
            "[076] train=0.0002 val=0.0001\n",
            "[077] train=0.0002 val=0.0000\n",
            "[078] train=0.0002 val=0.0001\n",
            "[079] train=0.0002 val=0.0001\n",
            "[080] train=0.0002 val=0.0001\n",
            "[081] train=0.0002 val=0.0001\n",
            "[082] train=0.0002 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.60 RMSE=31.63 sMAPE=55.14%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0010 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0005 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.99 RMSE=32.74 sMAPE=56.08%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0004 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0002\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0002\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0000\n",
            "[014] train=0.0003 val=0.0001\n",
            "[015] train=0.0003 val=0.0000\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0000\n",
            "[018] train=0.0003 val=0.0000\n",
            "[019] train=0.0003 val=0.0000\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.77 RMSE=32.01 sMAPE=55.07%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.73 RMSE=33.14 sMAPE=57.25%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0004\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.93 RMSE=33.26 sMAPE=57.53%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0013 val=0.0001\n",
            "[002] train=0.0007 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0004 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0001\n",
            "[046] train=0.0003 val=0.0001\n",
            "[047] train=0.0003 val=0.0001\n",
            "[048] train=0.0003 val=0.0001\n",
            "[049] train=0.0003 val=0.0001\n",
            "[050] train=0.0003 val=0.0001\n",
            "[051] train=0.0003 val=0.0001\n",
            "[052] train=0.0003 val=0.0001\n",
            "[053] train=0.0003 val=0.0001\n",
            "[054] train=0.0003 val=0.0001\n",
            "[055] train=0.0003 val=0.0001\n",
            "[056] train=0.0003 val=0.0001\n",
            "[057] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=24.97 RMSE=31.57 sMAPE=54.39%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0003\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0002\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.06 RMSE=32.05 sMAPE=56.58%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.78 RMSE=33.14 sMAPE=57.18%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0004\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.25 RMSE=31.49 sMAPE=55.23%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.78 RMSE=32.33 sMAPE=55.05%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0005\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0002\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0000\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0000\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0000\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0000\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0000\n",
            "[046] train=0.0002 val=0.0001\n",
            "[047] train=0.0003 val=0.0001\n",
            "[048] train=0.0002 val=0.0001\n",
            "[049] train=0.0002 val=0.0000\n",
            "[050] train=0.0002 val=0.0000\n",
            "[051] train=0.0002 val=0.0000\n",
            "[052] train=0.0002 val=0.0000\n",
            "[053] train=0.0002 val=0.0001\n",
            "[054] train=0.0002 val=0.0000\n",
            "[055] train=0.0002 val=0.0000\n",
            "[056] train=0.0002 val=0.0000\n",
            "[057] train=0.0002 val=0.0000\n",
            "[058] train=0.0002 val=0.0000\n",
            "[059] train=0.0002 val=0.0000\n",
            "[060] train=0.0002 val=0.0000\n",
            "→ early stopping\n",
            "[eval] MAE=25.01 RMSE=31.07 sMAPE=54.91%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0010 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0004 val=0.0001\n",
            "[030] train=0.0004 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.60 RMSE=33.19 sMAPE=57.48%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.60 RMSE=31.80 sMAPE=56.38%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0002\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0000\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.62 RMSE=31.95 sMAPE=55.79%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0003\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0002\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0003 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0002 val=0.0000\n",
            "[039] train=0.0002 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0002 val=0.0001\n",
            "[042] train=0.0002 val=0.0001\n",
            "[043] train=0.0002 val=0.0000\n",
            "[044] train=0.0002 val=0.0001\n",
            "[045] train=0.0002 val=0.0000\n",
            "[046] train=0.0002 val=0.0000\n",
            "[047] train=0.0002 val=0.0000\n",
            "[048] train=0.0002 val=0.0000\n",
            "[049] train=0.0002 val=0.0000\n",
            "[050] train=0.0002 val=0.0000\n",
            "[051] train=0.0002 val=0.0000\n",
            "[052] train=0.0002 val=0.0000\n",
            "[053] train=0.0002 val=0.0000\n",
            "[054] train=0.0002 val=0.0000\n",
            "[055] train=0.0002 val=0.0000\n",
            "[056] train=0.0002 val=0.0000\n",
            "[057] train=0.0002 val=0.0000\n",
            "[058] train=0.0002 val=0.0000\n",
            "[059] train=0.0002 val=0.0000\n",
            "[060] train=0.0002 val=0.0000\n",
            "[061] train=0.0002 val=0.0000\n",
            "[062] train=0.0002 val=0.0000\n",
            "[063] train=0.0002 val=0.0000\n",
            "[064] train=0.0002 val=0.0000\n",
            "[065] train=0.0002 val=0.0000\n",
            "[066] train=0.0002 val=0.0000\n",
            "[067] train=0.0002 val=0.0000\n",
            "[068] train=0.0002 val=0.0000\n",
            "[069] train=0.0002 val=0.0000\n",
            "→ early stopping\n",
            "[eval] MAE=24.80 RMSE=30.92 sMAPE=54.37%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0002\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.33 RMSE=32.69 sMAPE=56.84%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl24_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.71 RMSE=32.04 sMAPE=55.38%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0001\n",
            "[046] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.30 RMSE=32.84 sMAPE=56.41%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.34 RMSE=32.71 sMAPE=56.20%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0002\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=28.68 RMSE=35.49 sMAPE=60.82%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0001\n",
            "[046] train=0.0003 val=0.0001\n",
            "[047] train=0.0003 val=0.0001\n",
            "[048] train=0.0003 val=0.0001\n",
            "[049] train=0.0003 val=0.0001\n",
            "[050] train=0.0003 val=0.0001\n",
            "[051] train=0.0003 val=0.0001\n",
            "[052] train=0.0003 val=0.0001\n",
            "[053] train=0.0003 val=0.0001\n",
            "[054] train=0.0003 val=0.0001\n",
            "[055] train=0.0002 val=0.0001\n",
            "[056] train=0.0002 val=0.0001\n",
            "[057] train=0.0003 val=0.0001\n",
            "[058] train=0.0002 val=0.0001\n",
            "[059] train=0.0002 val=0.0001\n",
            "[060] train=0.0002 val=0.0001\n",
            "[061] train=0.0002 val=0.0001\n",
            "[062] train=0.0002 val=0.0001\n",
            "[063] train=0.0002 val=0.0001\n",
            "[064] train=0.0002 val=0.0001\n",
            "[065] train=0.0002 val=0.0001\n",
            "[066] train=0.0002 val=0.0001\n",
            "[067] train=0.0002 val=0.0001\n",
            "[068] train=0.0002 val=0.0001\n",
            "[069] train=0.0002 val=0.0001\n",
            "[070] train=0.0002 val=0.0001\n",
            "[071] train=0.0002 val=0.0001\n",
            "[072] train=0.0002 val=0.0001\n",
            "[073] train=0.0002 val=0.0001\n",
            "[074] train=0.0002 val=0.0001\n",
            "[075] train=0.0002 val=0.0001\n",
            "[076] train=0.0002 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.07 RMSE=31.34 sMAPE=54.59%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0010 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.04 RMSE=32.21 sMAPE=55.78%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0002\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.93 RMSE=32.29 sMAPE=55.46%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.11 RMSE=32.94 sMAPE=56.45%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.74 RMSE=32.10 sMAPE=55.31%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0001\n",
            "[046] train=0.0003 val=0.0001\n",
            "[047] train=0.0003 val=0.0000\n",
            "[048] train=0.0003 val=0.0000\n",
            "[049] train=0.0003 val=0.0000\n",
            "[050] train=0.0003 val=0.0000\n",
            "[051] train=0.0003 val=0.0001\n",
            "[052] train=0.0003 val=0.0001\n",
            "[053] train=0.0003 val=0.0001\n",
            "[054] train=0.0003 val=0.0001\n",
            "[055] train=0.0002 val=0.0000\n",
            "[056] train=0.0002 val=0.0000\n",
            "[057] train=0.0002 val=0.0000\n",
            "[058] train=0.0002 val=0.0000\n",
            "[059] train=0.0002 val=0.0000\n",
            "[060] train=0.0002 val=0.0000\n",
            "[061] train=0.0002 val=0.0000\n",
            "[062] train=0.0002 val=0.0000\n",
            "[063] train=0.0002 val=0.0001\n",
            "[064] train=0.0002 val=0.0000\n",
            "[065] train=0.0002 val=0.0000\n",
            "[066] train=0.0002 val=0.0000\n",
            "[067] train=0.0002 val=0.0001\n",
            "[068] train=0.0002 val=0.0000\n",
            "[069] train=0.0002 val=0.0000\n",
            "[070] train=0.0002 val=0.0000\n",
            "[071] train=0.0002 val=0.0000\n",
            "[072] train=0.0002 val=0.0000\n",
            "[073] train=0.0002 val=0.0000\n",
            "[074] train=0.0002 val=0.0000\n",
            "[075] train=0.0002 val=0.0000\n",
            "→ early stopping\n",
            "[eval] MAE=24.86 RMSE=30.99 sMAPE=53.66%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.11 RMSE=32.45 sMAPE=55.23%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0013 val=0.0002\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0005 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0004 val=0.0001\n",
            "[030] train=0.0004 val=0.0001\n",
            "[031] train=0.0004 val=0.0001\n",
            "[032] train=0.0004 val=0.0001\n",
            "[033] train=0.0004 val=0.0001\n",
            "[034] train=0.0004 val=0.0001\n",
            "[035] train=0.0004 val=0.0001\n",
            "[036] train=0.0004 val=0.0001\n",
            "[037] train=0.0004 val=0.0001\n",
            "[038] train=0.0004 val=0.0001\n",
            "[039] train=0.0004 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.61 RMSE=33.06 sMAPE=57.53%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=27.37 RMSE=33.55 sMAPE=57.52%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.05 RMSE=33.13 sMAPE=55.65%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.18 RMSE=31.94 sMAPE=54.85%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0002\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0004 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0004 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.76 RMSE=32.20 sMAPE=55.83%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl24_fl48_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0000\n",
            "[036] train=0.0003 val=0.0000\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0000\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0000\n",
            "[045] train=0.0002 val=0.0000\n",
            "[046] train=0.0003 val=0.0000\n",
            "[047] train=0.0002 val=0.0000\n",
            "[048] train=0.0002 val=0.0000\n",
            "[049] train=0.0002 val=0.0001\n",
            "[050] train=0.0002 val=0.0001\n",
            "[051] train=0.0002 val=0.0000\n",
            "[052] train=0.0002 val=0.0000\n",
            "[053] train=0.0002 val=0.0000\n",
            "[054] train=0.0002 val=0.0000\n",
            "[055] train=0.0002 val=0.0000\n",
            "[056] train=0.0002 val=0.0000\n",
            "[057] train=0.0002 val=0.0001\n",
            "[058] train=0.0002 val=0.0001\n",
            "[059] train=0.0002 val=0.0000\n",
            "[060] train=0.0002 val=0.0000\n",
            "[061] train=0.0002 val=0.0000\n",
            "[062] train=0.0002 val=0.0000\n",
            "[063] train=0.0002 val=0.0000\n",
            "[064] train=0.0002 val=0.0000\n",
            "[065] train=0.0002 val=0.0000\n",
            "[066] train=0.0002 val=0.0000\n",
            "[067] train=0.0002 val=0.0000\n",
            "[068] train=0.0002 val=0.0001\n",
            "[069] train=0.0002 val=0.0000\n",
            "[070] train=0.0002 val=0.0000\n",
            "[071] train=0.0002 val=0.0000\n",
            "[072] train=0.0002 val=0.0000\n",
            "[073] train=0.0002 val=0.0000\n",
            "[074] train=0.0002 val=0.0000\n",
            "[075] train=0.0002 val=0.0000\n",
            "[076] train=0.0002 val=0.0000\n",
            "[077] train=0.0002 val=0.0000\n",
            "[078] train=0.0002 val=0.0000\n",
            "[079] train=0.0002 val=0.0000\n",
            "[080] train=0.0002 val=0.0000\n",
            "[081] train=0.0002 val=0.0000\n",
            "[082] train=0.0002 val=0.0000\n",
            "[083] train=0.0002 val=0.0000\n",
            "[084] train=0.0002 val=0.0000\n",
            "[085] train=0.0002 val=0.0000\n",
            "[086] train=0.0002 val=0.0000\n",
            "[087] train=0.0002 val=0.0000\n",
            "[088] train=0.0002 val=0.0000\n",
            "[089] train=0.0002 val=0.0000\n",
            "[090] train=0.0002 val=0.0000\n",
            "[091] train=0.0002 val=0.0000\n",
            "[092] train=0.0002 val=0.0000\n",
            "[093] train=0.0002 val=0.0000\n",
            "[094] train=0.0002 val=0.0000\n",
            "[095] train=0.0002 val=0.0000\n",
            "[096] train=0.0002 val=0.0000\n",
            "[097] train=0.0002 val=0.0000\n",
            "[098] train=0.0002 val=0.0000\n",
            "[099] train=0.0002 val=0.0000\n",
            "[100] train=0.0002 val=0.0000\n",
            "[eval] MAE=25.36 RMSE=31.12 sMAPE=55.10%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0012 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.91 RMSE=33.02 sMAPE=57.19%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0000\n",
            "[035] train=0.0003 val=0.0000\n",
            "[036] train=0.0003 val=0.0000\n",
            "[037] train=0.0003 val=0.0000\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0002 val=0.0000\n",
            "[046] train=0.0002 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.38 RMSE=31.28 sMAPE=55.45%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0010 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0000\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0000\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.25 RMSE=31.43 sMAPE=54.88%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0002\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0003 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0001\n",
            "[046] train=0.0003 val=0.0001\n",
            "[047] train=0.0003 val=0.0001\n",
            "[048] train=0.0002 val=0.0001\n",
            "[049] train=0.0002 val=0.0001\n",
            "[050] train=0.0002 val=0.0001\n",
            "[051] train=0.0002 val=0.0001\n",
            "[052] train=0.0002 val=0.0001\n",
            "[053] train=0.0002 val=0.0001\n",
            "[054] train=0.0002 val=0.0001\n",
            "[055] train=0.0002 val=0.0001\n",
            "[056] train=0.0002 val=0.0001\n",
            "[057] train=0.0002 val=0.0001\n",
            "[058] train=0.0002 val=0.0001\n",
            "[059] train=0.0002 val=0.0000\n",
            "[060] train=0.0002 val=0.0001\n",
            "[061] train=0.0002 val=0.0001\n",
            "[062] train=0.0002 val=0.0000\n",
            "[063] train=0.0002 val=0.0001\n",
            "[064] train=0.0002 val=0.0001\n",
            "[065] train=0.0002 val=0.0001\n",
            "[066] train=0.0002 val=0.0000\n",
            "[067] train=0.0002 val=0.0000\n",
            "[068] train=0.0002 val=0.0000\n",
            "[069] train=0.0002 val=0.0000\n",
            "[070] train=0.0002 val=0.0000\n",
            "[071] train=0.0002 val=0.0001\n",
            "[072] train=0.0002 val=0.0001\n",
            "[073] train=0.0002 val=0.0000\n",
            "[074] train=0.0002 val=0.0000\n",
            "[075] train=0.0002 val=0.0001\n",
            "[076] train=0.0002 val=0.0001\n",
            "[077] train=0.0002 val=0.0000\n",
            "[078] train=0.0002 val=0.0001\n",
            "[079] train=0.0002 val=0.0000\n",
            "[080] train=0.0002 val=0.0001\n",
            "[081] train=0.0002 val=0.0000\n",
            "[082] train=0.0002 val=0.0000\n",
            "[083] train=0.0002 val=0.0000\n",
            "[084] train=0.0002 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.92 RMSE=33.20 sMAPE=56.21%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.44 RMSE=31.72 sMAPE=56.04%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.03 RMSE=31.96 sMAPE=56.42%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0010 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0005 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.04 RMSE=32.05 sMAPE=56.20%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0003 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0000\n",
            "[027] train=0.0003 val=0.0000\n",
            "[028] train=0.0003 val=0.0000\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0000\n",
            "[035] train=0.0003 val=0.0000\n",
            "[036] train=0.0003 val=0.0000\n",
            "[037] train=0.0003 val=0.0000\n",
            "→ early stopping\n",
            "[eval] MAE=25.16 RMSE=31.35 sMAPE=55.28%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0000\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0003 val=0.0000\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.57 RMSE=31.57 sMAPE=55.68%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.20 RMSE=31.26 sMAPE=55.22%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0010 val=0.0002\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0004 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.24 RMSE=32.47 sMAPE=56.91%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0003 val=0.0001\n",
            "[015] train=0.0003 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0003 val=0.0001\n",
            "[046] train=0.0003 val=0.0001\n",
            "[047] train=0.0002 val=0.0001\n",
            "[048] train=0.0003 val=0.0001\n",
            "[049] train=0.0002 val=0.0001\n",
            "[050] train=0.0002 val=0.0001\n",
            "[051] train=0.0002 val=0.0001\n",
            "[052] train=0.0002 val=0.0001\n",
            "[053] train=0.0002 val=0.0001\n",
            "[054] train=0.0002 val=0.0001\n",
            "[055] train=0.0002 val=0.0001\n",
            "[056] train=0.0002 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.22 RMSE=32.08 sMAPE=56.63%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0005 val=0.0001\n",
            "[007] train=0.0005 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0000\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0000\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0000\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.43 RMSE=31.45 sMAPE=56.16%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0000\n",
            "[013] train=0.0004 val=0.0000\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0000\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0000\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0000\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0000\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0000\n",
            "[036] train=0.0003 val=0.0000\n",
            "[037] train=0.0003 val=0.0000\n",
            "[038] train=0.0003 val=0.0000\n",
            "[039] train=0.0003 val=0.0000\n",
            "[040] train=0.0003 val=0.0000\n",
            "[041] train=0.0003 val=0.0000\n",
            "[042] train=0.0003 val=0.0000\n",
            "[043] train=0.0003 val=0.0000\n",
            "[044] train=0.0003 val=0.0000\n",
            "[045] train=0.0003 val=0.0000\n",
            "[046] train=0.0003 val=0.0000\n",
            "[047] train=0.0003 val=0.0000\n",
            "[048] train=0.0003 val=0.0001\n",
            "[049] train=0.0003 val=0.0000\n",
            "[050] train=0.0003 val=0.0000\n",
            "[051] train=0.0003 val=0.0000\n",
            "[052] train=0.0003 val=0.0000\n",
            "→ early stopping\n",
            "[eval] MAE=25.82 RMSE=31.64 sMAPE=55.95%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0000\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0003 val=0.0000\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0000\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.43 RMSE=32.45 sMAPE=56.83%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl24_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.65 RMSE=33.26 sMAPE=56.66%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0013 val=0.0002\n",
            "[002] train=0.0007 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0005 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.56 RMSE=32.61 sMAPE=56.63%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.61 RMSE=31.95 sMAPE=56.16%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.53 RMSE=32.62 sMAPE=55.14%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0000\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0002 val=0.0001\n",
            "[039] train=0.0002 val=0.0001\n",
            "[040] train=0.0002 val=0.0000\n",
            "[041] train=0.0002 val=0.0001\n",
            "[042] train=0.0002 val=0.0001\n",
            "[043] train=0.0002 val=0.0000\n",
            "[044] train=0.0002 val=0.0000\n",
            "[045] train=0.0002 val=0.0000\n",
            "[046] train=0.0002 val=0.0000\n",
            "[047] train=0.0002 val=0.0000\n",
            "[048] train=0.0002 val=0.0000\n",
            "[049] train=0.0002 val=0.0000\n",
            "[050] train=0.0002 val=0.0000\n",
            "[051] train=0.0002 val=0.0001\n",
            "[052] train=0.0002 val=0.0001\n",
            "[053] train=0.0002 val=0.0001\n",
            "[054] train=0.0002 val=0.0000\n",
            "[055] train=0.0002 val=0.0000\n",
            "[056] train=0.0002 val=0.0000\n",
            "[057] train=0.0002 val=0.0000\n",
            "[058] train=0.0002 val=0.0000\n",
            "[059] train=0.0002 val=0.0000\n",
            "[060] train=0.0002 val=0.0000\n",
            "[061] train=0.0002 val=0.0000\n",
            "[062] train=0.0002 val=0.0000\n",
            "[063] train=0.0002 val=0.0000\n",
            "[064] train=0.0002 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.53 RMSE=31.38 sMAPE=55.01%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=27.53 RMSE=33.66 sMAPE=58.96%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0002 val=0.0001\n",
            "[045] train=0.0002 val=0.0001\n",
            "[046] train=0.0002 val=0.0001\n",
            "[047] train=0.0002 val=0.0001\n",
            "[048] train=0.0002 val=0.0000\n",
            "[049] train=0.0002 val=0.0000\n",
            "[050] train=0.0002 val=0.0001\n",
            "[051] train=0.0002 val=0.0001\n",
            "[052] train=0.0002 val=0.0000\n",
            "[053] train=0.0002 val=0.0001\n",
            "[054] train=0.0002 val=0.0001\n",
            "[055] train=0.0002 val=0.0000\n",
            "[056] train=0.0002 val=0.0000\n",
            "[057] train=0.0002 val=0.0000\n",
            "[058] train=0.0002 val=0.0001\n",
            "[059] train=0.0002 val=0.0001\n",
            "[060] train=0.0002 val=0.0000\n",
            "[061] train=0.0002 val=0.0000\n",
            "[062] train=0.0002 val=0.0000\n",
            "[063] train=0.0002 val=0.0000\n",
            "[064] train=0.0002 val=0.0000\n",
            "[065] train=0.0002 val=0.0000\n",
            "→ early stopping\n",
            "[eval] MAE=25.18 RMSE=30.95 sMAPE=54.49%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.73 RMSE=33.10 sMAPE=57.47%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh32_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0003 val=0.0001\n",
            "[015] train=0.0003 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0000\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0000\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0000\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0000\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0001\n",
            "[043] train=0.0003 val=0.0001\n",
            "[044] train=0.0003 val=0.0001\n",
            "[045] train=0.0002 val=0.0000\n",
            "[046] train=0.0002 val=0.0001\n",
            "[047] train=0.0002 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=25.05 RMSE=31.09 sMAPE=54.52%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0012 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0004 val=0.0001\n",
            "[030] train=0.0004 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0001\n",
            "[041] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.23 RMSE=32.24 sMAPE=56.17%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0004 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.78 RMSE=33.44 sMAPE=58.33%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.95 RMSE=33.34 sMAPE=57.06%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh32_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0008 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.39 RMSE=32.75 sMAPE=57.55%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad32_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "[017] train=0.0004 val=0.0001\n",
            "[018] train=0.0004 val=0.0001\n",
            "[019] train=0.0004 val=0.0001\n",
            "[020] train=0.0004 val=0.0001\n",
            "[021] train=0.0004 val=0.0001\n",
            "[022] train=0.0004 val=0.0001\n",
            "[023] train=0.0004 val=0.0001\n",
            "[024] train=0.0004 val=0.0001\n",
            "[025] train=0.0004 val=0.0001\n",
            "[026] train=0.0004 val=0.0001\n",
            "[027] train=0.0004 val=0.0001\n",
            "[028] train=0.0004 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.62 RMSE=33.02 sMAPE=57.68%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad32_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0007 val=0.0001\n",
            "[002] train=0.0005 val=0.0001\n",
            "[003] train=0.0005 val=0.0002\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0004 val=0.0001\n",
            "[006] train=0.0004 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0002\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0003 val=0.0001\n",
            "[017] train=0.0003 val=0.0001\n",
            "[018] train=0.0003 val=0.0001\n",
            "[019] train=0.0003 val=0.0001\n",
            "[020] train=0.0003 val=0.0001\n",
            "[021] train=0.0003 val=0.0001\n",
            "[022] train=0.0003 val=0.0001\n",
            "[023] train=0.0003 val=0.0001\n",
            "[024] train=0.0003 val=0.0001\n",
            "[025] train=0.0003 val=0.0001\n",
            "[026] train=0.0003 val=0.0001\n",
            "[027] train=0.0003 val=0.0001\n",
            "[028] train=0.0003 val=0.0001\n",
            "[029] train=0.0003 val=0.0001\n",
            "[030] train=0.0003 val=0.0001\n",
            "[031] train=0.0003 val=0.0001\n",
            "[032] train=0.0003 val=0.0001\n",
            "[033] train=0.0003 val=0.0001\n",
            "[034] train=0.0003 val=0.0001\n",
            "[035] train=0.0003 val=0.0001\n",
            "[036] train=0.0003 val=0.0001\n",
            "[037] train=0.0003 val=0.0001\n",
            "[038] train=0.0003 val=0.0001\n",
            "[039] train=0.0003 val=0.0001\n",
            "[040] train=0.0003 val=0.0000\n",
            "[041] train=0.0003 val=0.0001\n",
            "[042] train=0.0003 val=0.0000\n",
            "[043] train=0.0003 val=0.0000\n",
            "[044] train=0.0003 val=0.0000\n",
            "[045] train=0.0003 val=0.0000\n",
            "[046] train=0.0002 val=0.0000\n",
            "[047] train=0.0002 val=0.0001\n",
            "[048] train=0.0002 val=0.0000\n",
            "[049] train=0.0002 val=0.0000\n",
            "[050] train=0.0002 val=0.0000\n",
            "[051] train=0.0002 val=0.0000\n",
            "[052] train=0.0002 val=0.0000\n",
            "[053] train=0.0002 val=0.0000\n",
            "[054] train=0.0002 val=0.0000\n",
            "[055] train=0.0002 val=0.0000\n",
            "[056] train=0.0002 val=0.0001\n",
            "[057] train=0.0002 val=0.0000\n",
            "[058] train=0.0002 val=0.0000\n",
            "[059] train=0.0002 val=0.0000\n",
            "[060] train=0.0002 val=0.0000\n",
            "[061] train=0.0002 val=0.0001\n",
            "[062] train=0.0002 val=0.0000\n",
            "[063] train=0.0002 val=0.0001\n",
            "[064] train=0.0002 val=0.0000\n",
            "[065] train=0.0002 val=0.0000\n",
            "[066] train=0.0002 val=0.0000\n",
            "[067] train=0.0002 val=0.0000\n",
            "[068] train=0.0002 val=0.0000\n",
            "[069] train=0.0002 val=0.0000\n",
            "→ early stopping\n",
            "[eval] MAE=25.11 RMSE=30.82 sMAPE=54.10%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad64_nl1_bs96_lr.001_me100_p10_MaxAbs_MSE\n",
            "\n",
            "🚀 Starting run: saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n",
            "[001] train=0.0009 val=0.0001\n",
            "[002] train=0.0006 val=0.0001\n",
            "[003] train=0.0005 val=0.0001\n",
            "[004] train=0.0005 val=0.0001\n",
            "[005] train=0.0005 val=0.0001\n",
            "[006] train=0.0005 val=0.0001\n",
            "[007] train=0.0004 val=0.0001\n",
            "[008] train=0.0004 val=0.0001\n",
            "[009] train=0.0004 val=0.0001\n",
            "[010] train=0.0004 val=0.0001\n",
            "[011] train=0.0004 val=0.0001\n",
            "[012] train=0.0004 val=0.0001\n",
            "[013] train=0.0004 val=0.0001\n",
            "[014] train=0.0004 val=0.0001\n",
            "[015] train=0.0004 val=0.0001\n",
            "[016] train=0.0004 val=0.0001\n",
            "→ early stopping\n",
            "[eval] MAE=26.23 RMSE=32.72 sMAPE=56.53%\n",
            "✅ saved all outputs to saved_runs/BiAttnPointForecaster_sl48_fl48_h4_lh64_dh64_ad64_nl1_bs256_lr.001_me100_p10_MaxAbs_MSE\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, MaxAbsScaler\n",
        "from itertools import product\n",
        "\n",
        "from src.models.factory import MODEL_FACTORY\n",
        "from src.datasets.datasets import MultiFeedDataset\n",
        "from src.models.SA_BiLSTM import SA_BiLSTM\n",
        "from src.models.BiAttnPointForecaster import BiAttnPointForecaster\n",
        "\n",
        "\n",
        "# ─── configuration ──────────────────────────────────────────────────────────────\n",
        "root           = Path(\".\")\n",
        "forecast_dir   = root / \"bmrs_csv_filled\"\n",
        "df_path        = root / forecast_dir / \"df_all.csv\"\n",
        "mask_dir       = root / \"bmrs_csv_masks\"\n",
        "\n",
        "date_start     = \"2021-07-01\"\n",
        "date_end       = \"2025-06-30\"\n",
        "train_end_date = \"2025-03-01\"\n",
        "val_end_date   = \"2025-05-01\"\n",
        "\n",
        "horizon        = 48\n",
        "use_time_feat  = False   # whether to add trig-based time features\n",
        "\n",
        "# ─── sanity checks & seeding ───────────────────────────────────────────────────\n",
        "assert df_path.exists(), f\"{df_path} not found\"\n",
        "for d in (forecast_dir, mask_dir):\n",
        "    assert d.exists(), f\"{d} not found\"\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "df = (\n",
        "    pd.read_csv(df_path, index_col=\"startTime\", parse_dates=True)\n",
        "      .loc[date_start:date_end]\n",
        ")\n",
        "print(f\"[debug] loaded df rows = {len(df)}\")\n",
        "\n",
        "# drop any forecast/actual cols\n",
        "to_drop = [c for c in df.columns if \"forecast\" in c.lower() or \"actual\" in c.lower()]\n",
        "df.drop(columns=to_drop, errors=\"ignore\", inplace=True)\n",
        "\n",
        "# embed time features\n",
        "df[\"month_idx\"]   = df.index.month - 1\n",
        "df[\"weekday_idx\"] = df.index.dayofweek\n",
        "if \"settlement period\" in (c.lower() for c in df.columns):\n",
        "    df[\"sp_idx\"] = df.pop(\"Settlement Period\").astype(int) - 1\n",
        "else:\n",
        "    df[\"sp_idx\"] = 0\n",
        "    print(\"[warn] 'settlement period' not found; sp_idx set to 0\")\n",
        "df[\"dtype_idx\"]   = (df.index.dayofweek >= 5).astype(int)\n",
        "\n",
        "print(df[[\"month_idx\",\"weekday_idx\",\"sp_idx\",\"dtype_idx\"]].head())\n",
        "\n",
        "def load_forecast_matrix(name, prefix, idx, horizon):\n",
        "    path = forecast_dir / f\"{name}.csv\"\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"{path} not found\")\n",
        "    fdf = (\n",
        "        pd.read_csv(path, index_col=\"startTime\", parse_dates=True)\n",
        "          .loc[date_start:date_end]\n",
        "          .reindex(idx)\n",
        "    )\n",
        "    print(f\"[debug] {name}: {len(fdf)} rows reindexed\")\n",
        "    cols    = [f\"{prefix}_f{i}\" for i in range(1, horizon+1)]\n",
        "    present = [c for c in cols if c in fdf.columns]\n",
        "    mat     = fdf[present].fillna(0).to_numpy()\n",
        "    if mat.shape[1] < horizon:\n",
        "        pad = np.zeros((len(mat), horizon - mat.shape[1]), dtype=mat.dtype)\n",
        "        mat = np.hstack([mat, pad])\n",
        "        print(f\"[debug] {name}: padded from {len(present)}→{horizon}\")\n",
        "    else:\n",
        "        print(f\"[debug] {name}: full horizon loaded\")\n",
        "    return mat\n",
        "\n",
        "idx        = df.index\n",
        "demand_mat = load_forecast_matrix(\"DEMAND_FORECASTS\", \"demand\", idx, horizon)\n",
        "wind_mat   = load_forecast_matrix(\"WIND_FORECASTS\",   \"wind\",   idx, horizon)\n",
        "drm_mat    = load_forecast_matrix(\"DRM_FORECASTS\",    \"drm\",    idx, horizon)\n",
        "x_fut      = np.stack([demand_mat, wind_mat, drm_mat], axis=2)\n",
        "assert x_fut.shape[0] == len(df)\n",
        "print(f\"[debug] x_fut shape = {x_fut.shape}\")\n",
        "\n",
        "target_col = \"Imbalance Price\"\n",
        "assert target_col in df.columns, f\"missing target: {target_col}\"\n",
        "\n",
        "masks = {\n",
        "    \"train\": df.index < train_end_date,\n",
        "    \"val\"  : (df.index >= train_end_date) & (df.index < val_end_date),\n",
        "    \"test\" : df.index >= val_end_date,\n",
        "}\n",
        "\n",
        "cal_cols  = [\"month_idx\",\"weekday_idx\",\"sp_idx\",\"dtype_idx\"]\n",
        "hist_cols = [c for c in df.columns if c not in cal_cols]\n",
        "\n",
        "splits = {}\n",
        "for split, mask in masks.items():\n",
        "    sub = df.loc[mask]\n",
        "    splits[split] = {\n",
        "        \"x_hist\": sub[hist_cols].to_numpy(),\n",
        "        \"x_cal\" : sub[cal_cols].to_numpy(),\n",
        "        \"y\"     : sub[target_col].to_numpy(),\n",
        "        \"x_fut\" : x_fut[mask],\n",
        "    }\n",
        "    print(\n",
        "        f\"{split:5s} → \"\n",
        "        f\"x_hist {splits[split]['x_hist'].shape}, \"\n",
        "        f\"x_cal {splits[split]['x_cal'].shape}, \"\n",
        "        f\"y {splits[split]['y'].shape}, \"\n",
        "        f\"x_fut {splits[split]['x_fut'].shape}\"\n",
        "    )\n",
        "\n",
        "# ─── grid of hyperparameters ──────────────────────────────────────────────────\n",
        "param_grid = {\n",
        "    \"seq_len\":      [24, 48],\n",
        "    \"feed_len\":     [24, 48],\n",
        "    \"fut_len\":      [4],\n",
        "    \"lstm_hidden\":  [32, 64],\n",
        "    \"dec_hidden\":   [32, 64],\n",
        "    \"attn_dim\":     [32, 64],\n",
        "    \"num_layers\":   [1],\n",
        "    \"dropout\":      [0.0],\n",
        "    \"batch_size\":   [96, 256],\n",
        "    \"learning_rate\": [1e-3],\n",
        "    \"patience\": [10],\n",
        "    \"max_epochs\": [100],\n",
        "    \"scaler_used\":  [\"MaxAbs\"],\n",
        "    \"loss_used\":    [\"MSE\",],\n",
        "    \"beta\":         [None]  # only used if loss == Huber\n",
        "}\n",
        "\n",
        "grid = list(product(*param_grid.values()))\n",
        "param_names = list(param_grid.keys())\n",
        "\n",
        "transformer_factory = {\n",
        "    \"MinMax\":   MinMaxScaler,\n",
        "    \"Robust\":   RobustScaler,\n",
        "    \"Standard\": StandardScaler,\n",
        "    \"MaxAbs\":   MaxAbsScaler,\n",
        "}\n",
        "\n",
        "loss_factory = {\n",
        "    \"MAE\":   nn.L1Loss,\n",
        "    \"MSE\":   nn.MSELoss,\n",
        "    \"Huber\": nn.SmoothL1Loss,\n",
        "}\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "import joblib\n",
        "import json\n",
        "import copy\n",
        "import platform\n",
        "\n",
        "def run_experiment(config):\n",
        "\n",
        "    for k, v in config.items():\n",
        "        globals()[k] = v\n",
        "\n",
        "    # ─── Now construct metadata dict correctly ─────────────────────\n",
        "    md = {\n",
        "        \"model\":        \"BiAttnPointForecaster\",\n",
        "        \"seq_len\":      seq_len,\n",
        "        \"feed_len\":     feed_len,\n",
        "        \"horizon\":      fut_len,\n",
        "        \"lstm_hidden\":  lstm_hidden,\n",
        "        \"dec_hidden\":   dec_hidden,\n",
        "        \"attn_dim\":     attn_dim,\n",
        "        \"num_layers\":   num_layers,\n",
        "        \"batch_size\":   batch_size,\n",
        "        \"learning_rate\":learning_rate,\n",
        "        \"max_epochs\":   100,\n",
        "        \"patience\":     10,\n",
        "        \"scaler\":       scaler_used,\n",
        "        \"loss\":         loss_used,\n",
        "        **({\"beta\": beta} if loss_used == \"Huber\" else {}),\n",
        "    }\n",
        "\n",
        "    initials = lambda s: \"\".join(w[0] for w in s.split(\"_\"))\n",
        "    parts = []\n",
        "    for k, v in md.items():\n",
        "        sv = str(v)\n",
        "        if isinstance(v, float) and sv.startswith(\"0.\"):\n",
        "            sv = sv.replace(\"0.\", \".\")\n",
        "        part = sv if k in {\"model\", \"scaler\", \"loss\", \"notes\"} else f\"{initials(k)}{sv}\"\n",
        "        parts.append(part)\n",
        "    tag = \"_\".join(parts)\n",
        "\n",
        "    models_root = Path(\"saved_runs\")\n",
        "    base_dir = models_root / tag\n",
        "    version = 0\n",
        "    while base_dir.exists():\n",
        "        version += 1\n",
        "        base_dir = models_root / f\"{tag}_v{version}\"\n",
        "    base_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"\\n🚀 Starting run: {base_dir}\")\n",
        "\n",
        "    # ─── Data Scaling ─────────────────────────────────────────────\n",
        "    # ─── Data Scaling ─────────────────────────────────────────────\n",
        "    scaler_x = transformer_factory[scaler_used]()\n",
        "    scaler_f = transformer_factory[scaler_used]()\n",
        "    scaler_y = transformer_factory[scaler_used]()\n",
        "\n",
        "    # Fit only on training split to avoid data leakage\n",
        "    scaler_x.fit(splits[\"train\"][\"x_hist\"])\n",
        "    scaler_f.fit(splits[\"train\"][\"x_fut\"].reshape(-1, splits[\"train\"][\"x_fut\"].shape[2]))\n",
        "    scaler_y.fit(splits[\"train\"][\"y\"].reshape(-1, 1))\n",
        "\n",
        "    def scale_split(split):\n",
        "        x_hist = scaler_x.transform(splits[split][\"x_hist\"])\n",
        "        x_fut = splits[split][\"x_fut\"].reshape(-1, splits[split][\"x_fut\"].shape[2])\n",
        "        x_fut = scaler_f.transform(x_fut).reshape(splits[split][\"x_fut\"].shape)\n",
        "        y = scaler_y.transform(splits[split][\"y\"].reshape(-1, 1)).flatten()\n",
        "        return x_hist, x_fut, y\n",
        "\n",
        "    x_train_hist, x_fut_train, y_train = scale_split(\"train\")\n",
        "    x_val_hist,   x_fut_val,   y_val   = scale_split(\"val\")\n",
        "    x_test_hist,  x_fut_test,  y_test  = scale_split(\"test\")\n",
        "\n",
        "    def to_tensor(x, dtype):\n",
        "        return torch.tensor(x, dtype=dtype)\n",
        "\n",
        "    def make_dataset(xh, xf, y, split):\n",
        "        return MultiFeedDataset(\n",
        "            hist        = to_tensor(xh, torch.float32),\n",
        "            full_fut    = to_tensor(xf, torch.float32),\n",
        "            y           = to_tensor(y,  torch.float32),\n",
        "            month_idx   = to_tensor(splits[split][\"x_cal\"][:,0], torch.long),\n",
        "            weekday_idx = to_tensor(splits[split][\"x_cal\"][:,1], torch.long),\n",
        "            sp_idx      = to_tensor(splits[split][\"x_cal\"][:,2], torch.long),\n",
        "            dtype_idx   = to_tensor(splits[split][\"x_cal\"][:,3], torch.long),\n",
        "            seq_len     = seq_len,\n",
        "            feed_len    = feed_len,\n",
        "            fut_len     = fut_len\n",
        "        )\n",
        "\n",
        "    train_loader = DataLoader(make_dataset(x_train_hist, x_fut_train, y_train, \"train\"), batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(make_dataset(x_val_hist, x_fut_val, y_val, \"val\"),       batch_size=batch_size)\n",
        "    test_loader  = DataLoader(make_dataset(x_test_hist, x_fut_test, y_test, \"test\"),   batch_size=batch_size)\n",
        "\n",
        "    # ─── Model Setup ──────────────────────────────────────────────\n",
        "    time_feat_dim = 4 + 3 + 6 + 2  # 15\n",
        "\n",
        "    model = MODEL_FACTORY[\"BiAttnPointForecaster\"](\n",
        "        num_hist_feats = x_train_hist.shape[1],\n",
        "        num_fut_feats  = x_fut_train.shape[2],\n",
        "        time_feat_dim  = time_feat_dim,\n",
        "        lstm_hidden    = lstm_hidden,\n",
        "        dec_hidden     = dec_hidden,\n",
        "        attn_dim       = attn_dim,\n",
        "        hist_len       = seq_len,\n",
        "        feed_len       = feed_len,\n",
        "        fut_len        = fut_len,\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = loss_factory[loss_used](beta=beta) if loss_used == \"Huber\" else loss_factory[loss_used]()\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-7)\n",
        "\n",
        "    # ─── Training Loop ────────────────────────────────────────────\n",
        "    best_val, best_ckpt, epochs_no_improve = float(\"inf\"), None, 0\n",
        "    for epoch in range(1, 101):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for x_h, x_f, y_t, mi, wi, si, di in train_loader:\n",
        "            x_h, x_f, y_t = x_h.to(device), x_f.to(device), y_t.to(device)\n",
        "            mi, wi, si, di = mi.to(device), wi.to(device), si.to(device), di.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x_h, x_f, mi, wi, si, di)\n",
        "            loss = criterion(out, y_t)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x_h, x_f, y_t, mi, wi, si, di in val_loader:\n",
        "                x_h, x_f, y_t = x_h.to(device), x_f.to(device), y_t.to(device)\n",
        "                mi, wi, si, di = mi.to(device), wi.to(device), si.to(device), di.to(device)\n",
        "                out = model(x_h, x_f, mi, wi, si, di)\n",
        "                total_val_loss += criterion(out, y_t).item()\n",
        "\n",
        "        val_loss = total_val_loss / len(val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"[{epoch:03d}] train={train_loss:.4f} val={val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            best_ckpt = {\n",
        "                \"model\": copy.deepcopy(model.state_dict()),\n",
        "                \"optimizer\": copy.deepcopy(optimizer.state_dict())\n",
        "            }\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= 10:\n",
        "                print(\"→ early stopping\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_ckpt[\"model\"])\n",
        "\n",
        "    # ─── Evaluation ───────────────────────────────────────────────\n",
        "    model.eval()\n",
        "    preds_all, trues_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for x_h, x_f, y_t, mi, wi, si, di in test_loader:\n",
        "            x_h, x_f = x_h.to(device), x_f.to(device)\n",
        "            mi, wi, si, di = mi.to(device), wi.to(device), si.to(device), di.to(device)\n",
        "            out = model(x_h, x_f, mi, wi, si, di)\n",
        "            preds_all.append(out.cpu().numpy())\n",
        "            trues_all.append(y_t.numpy())\n",
        "\n",
        "    preds_all = np.concatenate(preds_all, axis=0)\n",
        "    trues_all = np.concatenate(trues_all, axis=0)\n",
        "\n",
        "    preds_orig = scaler_y.inverse_transform(preds_all.reshape(-1, 1)).flatten()\n",
        "    trues_orig = scaler_y.inverse_transform(trues_all.reshape(-1, 1)).flatten()\n",
        "    errors = trues_orig - preds_orig\n",
        "\n",
        "    mae = np.mean(np.abs(errors))\n",
        "    rmse = np.sqrt(np.mean(errors**2))\n",
        "    smape = np.mean(2.0 * np.abs(errors) / (np.abs(trues_orig) + np.abs(preds_orig) + 1e-8)) * 100\n",
        "\n",
        "    print(f\"[eval] MAE={mae:.2f} RMSE={rmse:.2f} sMAPE={smape:.2f}%\")\n",
        "\n",
        "    # ─── Save Full Metadata ─────────────────────────────────────────────────\n",
        "    class NpTorchJSONEncoder(json.JSONEncoder):\n",
        "        def default(self, o):\n",
        "            if isinstance(o, np.generic):   return o.item()\n",
        "            if isinstance(o, np.ndarray):   return o.tolist()\n",
        "            if isinstance(o, torch.Tensor): return o.detach().cpu().tolist()\n",
        "            if isinstance(o, torch.device): return str(o)\n",
        "            if isinstance(o, datetime):     return o.isoformat()\n",
        "            return super().default(o)\n",
        "\n",
        "    env_meta = {\n",
        "        \"seed_torch\":          torch.initial_seed(),\n",
        "        \"seed_numpy\":          np.random.get_state()[1][0],\n",
        "        \"seed_python\":         random.getstate()[1][0],\n",
        "        \"cudnn_deterministic\": getattr(torch.backends.cudnn, \"deterministic\", None),\n",
        "        \"cudnn_benchmark\":     getattr(torch.backends.cudnn, \"benchmark\", None),\n",
        "        \"torch_version\":       torch.__version__,\n",
        "        \"python_version\":      platform.python_version(),\n",
        "        \"run_timestamp\":       datetime.now(timezone.utc).isoformat()\n",
        "    }\n",
        "\n",
        "    df_train = df.loc[masks[\"train\"]]\n",
        "    df_test  = df.loc[masks[\"test\"]]\n",
        "\n",
        "    data_meta = {\n",
        "        \"start\":     df_train.index.min().strftime(\"%Y-%m-%d\"),\n",
        "        \"train_end\": train_end_date,\n",
        "        \"val_end\":   val_end_date,\n",
        "        \"end\":       df_test.index.max().strftime(\"%Y-%m-%d\"),\n",
        "        \"n_train\":   len(train_loader.dataset),\n",
        "        \"n_val\":     len(val_loader.dataset),\n",
        "        \"n_test\":    len(test_loader.dataset)\n",
        "    }\n",
        "\n",
        "    feat_meta = {\n",
        "        \"hist_feats\": {\n",
        "            \"cols\": hist_cols,\n",
        "            \"n\": x_train_hist.shape[1]\n",
        "        },\n",
        "        \"time_feats\": {\n",
        "            \"cols\": cal_cols,\n",
        "            \"n\": time_feat_dim,\n",
        "        },\n",
        "        \"fut_feats\": {\n",
        "            \"prefixes\": [\"demand\", \"wind\", \"drm\"],\n",
        "            \"n\": x_fut_train.shape[2],\n",
        "            \"feed_len\": feed_len,\n",
        "            \"fut_len\": fut_len\n",
        "        },\n",
        "        \"total_feats\": len(hist_cols) + len(cal_cols) + x_fut_train.shape[2]\n",
        "    }\n",
        "\n",
        "    loader_meta = {\n",
        "        \"batch_size\":  batch_size,\n",
        "        \"shuffle\":     {\"train\": True, \"val\": False, \"test\": False},\n",
        "        \"num_workers\": os.cpu_count() or 1,\n",
        "        \"pin_memory\":  True,\n",
        "        \"device\":      str(device),\n",
        "    }\n",
        "\n",
        "    hyperparams_meta = {\n",
        "        \"model\":         \"BiAttnPointForecaster\",\n",
        "        \"seq_len\":       seq_len,\n",
        "        \"feed_len\":      feed_len,\n",
        "        \"horizon\":       fut_len,\n",
        "        \"lstm_hidden\":   lstm_hidden,\n",
        "        \"dec_hidden\":    dec_hidden,\n",
        "        \"attn_dim\":      attn_dim,\n",
        "        \"num_layers\":    num_layers,\n",
        "        \"batch_size\":    batch_size,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"scaler\":        scaler_used,\n",
        "        \"loss\":          loss_used,\n",
        "        **({\"beta\": beta} if loss_used == \"Huber\" else {})\n",
        "    }\n",
        "\n",
        "    optim_meta = {\n",
        "        \"type\": optimizer.__class__.__name__,\n",
        "        \"lr\":   optimizer.defaults.get(\"lr\"),\n",
        "        **{k: optimizer.defaults[k]\n",
        "        for k in (\"betas\", \"eps\", \"weight_decay\")\n",
        "        if k in optimizer.defaults}\n",
        "    }\n",
        "\n",
        "    sched_meta = {\n",
        "        \"type\":     scheduler.__class__.__name__,\n",
        "        \"mode\":     getattr(scheduler, \"mode\", None),\n",
        "        \"factor\":   getattr(scheduler, \"factor\", None),\n",
        "        \"patience\": getattr(scheduler, \"patience\", None),\n",
        "        \"min_lr\":   (scheduler.min_lrs[0]\n",
        "                    if hasattr(scheduler, \"min_lrs\")\n",
        "                    else getattr(scheduler, \"eta_min\", None)),\n",
        "        \"last_lr\":  scheduler.get_last_lr()\n",
        "    }\n",
        "\n",
        "    earlystop_meta = {\n",
        "        \"max_epochs\": 200,\n",
        "        \"patience\":  20,\n",
        "        \"final_epoch\": epoch,\n",
        "        \"best_epoch\": epoch - epochs_no_improve\n",
        "    }\n",
        "\n",
        "    metrics_meta = {\n",
        "        \"mae\":   float(mae),\n",
        "        \"rmse\":  float(rmse),\n",
        "        \"smape\": float(smape),\n",
        "        \"huber\": float(np.mean(np.where(np.abs(errors) <= beta,\n",
        "                                        0.5 * errors**2 / beta,\n",
        "                                        np.abs(errors) - 0.5 * beta))) if loss_used == \"Huber\" else None\n",
        "    }\n",
        "\n",
        "    # Save everything\n",
        "    torch.save({\n",
        "        \"model_state_dict\":     model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"scheduler_state_dict\": scheduler.state_dict()\n",
        "    }, base_dir / \"torch_model.pt\")\n",
        "\n",
        "    joblib.dump({\n",
        "        \"scaler_x\": scaler_x,\n",
        "        \"scaler_f\": scaler_f,\n",
        "        \"scaler_y\": scaler_y\n",
        "    }, str(base_dir / \"scalers.joblib\"))\n",
        "\n",
        "    with open(base_dir / \"test_summary.json\", \"w\") as f:\n",
        "        json.dump({\n",
        "            \"environment\":  env_meta,\n",
        "            \"data\":         data_meta,\n",
        "            \"features\":     feat_meta,\n",
        "            \"dataloader\":   loader_meta,\n",
        "            \"hyperparams\":  hyperparams_meta,\n",
        "            \"optimizer\":    optim_meta,\n",
        "            \"scheduler\":    sched_meta,\n",
        "            \"early_stop\":   earlystop_meta,\n",
        "            \"metrics\":      metrics_meta\n",
        "        }, f, indent=2, cls=NpTorchJSONEncoder)\n",
        "\n",
        "    print(f\"✅ saved all outputs to {base_dir}\")\n",
        "\n",
        "\n",
        "\n",
        "# ─── Run All Configs ─────────────────────────────────────────────────────────\n",
        "for i, values in enumerate(grid):\n",
        "    config = dict(zip(param_names, values))\n",
        "    if config[\"loss_used\"] != \"Huber\":\n",
        "        config[\"beta\"] = None  # not applicable\n",
        "    try:\n",
        "        run_experiment(config)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Run {i+1}/{len(grid)} failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0899340",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (thesis)",
      "language": "python",
      "name": "thesis"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
