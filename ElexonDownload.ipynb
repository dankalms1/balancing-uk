{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad53b62a-3ce0-47e8-8b82-83e65cbf5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================  High-throughput Elexon bulk crawler  ==================\n",
    "import asyncio, aiohttp, gzip, json, datetime as dt\n",
    "from pathlib import Path\n",
    "import nest_asyncio, aiolimiter\n",
    "nest_asyncio.apply()           # lets us await main() directly in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1abc363-45af-4771-9de8-4ef9bea87cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://data.elexon.co.uk/bmrs/api/v1\"\n",
    "\n",
    "ENDPOINTS = {\n",
    "\n",
    "    # ------------------ Generation ----------------------------------------\n",
    "    \"GEN_PER_TYPE\":\n",
    "        \"/datasets/AGPT?\"\n",
    "        \"publishDateTimeFrom={from_ts}&publishDateTimeTo={to_ts}\",\n",
    "\n",
    "    \"INTER\":\n",
    "        \"/generation/outturn/interconnectors?\"\n",
    "        \"settlementDateFrom={date}&settlementDateTo={date}\",\n",
    "\n",
    "    \"DAYAHEAD_GEN_WIND_SOLAR\":\n",
    "        \"/forecast/generation/wind-and-solar/day-ahead?\"\n",
    "        \"from={from_ts}&to={to_ts}&processType=all\",\n",
    "\n",
    "    \"ACTUAL_GEN_WIND_SOLAR\":\n",
    "        \"/datasets/AGWS?publishDateTimeFrom={from_ts}&publishDateTimeTo={to_ts}\",\n",
    "\n",
    "    # ------------------ Demand -------------------------------------------\n",
    "    \"DAYAHEAD_DEMAND\":\n",
    "        \"/forecast/demand/day-ahead/history?\"\n",
    "        \"publishTime={date}\",\n",
    "\n",
    "    \"INDICATED_DAYAHEAD_DEMAND\":\n",
    "        \"/forecast/indicated/day-ahead/history?\"\n",
    "        \"publishTime={date}\",\n",
    "\n",
    "    \"ACTUAL_DEMAND\":\n",
    "        \"/demand/outturn?\"\n",
    "        \"settlementDateFrom={date}&settlementDateTo={date}\",\n",
    "\n",
    "    # ------------------ Balancing ----------------------------------------\n",
    "    \"SYSTEM_PRICES\":\n",
    "        \"/balancing/settlement/system-prices/{date}\",\n",
    "\n",
    "    \"BSAD\":\n",
    "        \"/datasets/netbsad?from={from_ts}&to={to_ts}\",\n",
    "\n",
    "    \"MID\":\n",
    "        \"/datasets/mid?from={from_ts}&to={to_ts}\",\n",
    "\n",
    "    \"NONBM\":\n",
    "        \"/datasets/NONBM?from={from_ts}&to={to_ts}\",\n",
    "\n",
    "    # ------------------ Transmission -------------------------------------\n",
    "    \"LOLPDRM\":\n",
    "        \"/forecast/system/loss-of-load?from={from_ts}&to={to_ts}\",\n",
    "}\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "START_DATE = dt.date(2019, 1, 1)\n",
    "END_DATE   = dt.date(2025, 5, 31)\n",
    "\n",
    "BASE_DIR = Path(\"bmrs_raw\")\n",
    "BASE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def _ph(day: dt.date):\n",
    "    \"\"\"Return placeholders dict for a given date.\"\"\"\n",
    "    iso = day.isoformat()\n",
    "    return {\n",
    "        \"date\"   : iso,\n",
    "        \"from_ts\": f\"{iso}T00:00:00Z\",\n",
    "        \"to_ts\"  : f\"{iso}T23:59:59Z\",\n",
    "    }\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "CONCURRENCY = 256                 # sockets\n",
    "PER_MINUTE  = aiolimiter.AsyncLimiter(4500, 60)   # 4 500 / 60 s\n",
    "PER_SECOND  = aiolimiter.AsyncLimiter(75,   1)    # 70   / 1 s   ← new\n",
    "TIMEOUT     = aiohttp.ClientTimeout(total=40)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "async def _fetch(sess: aiohttp.ClientSession, url: str, dest: Path, log: Path):\n",
    "    if dest.exists():\n",
    "        return\n",
    "\n",
    "    # acquire from **both** buckets\n",
    "    async with PER_SECOND, PER_MINUTE:\n",
    "        async with sess.get(url) as r:\n",
    "            if r.status == 404:\n",
    "                return\n",
    "            if r.status == 429:\n",
    "                # simple exponential back-off then retry once\n",
    "                await asyncio.sleep(5)\n",
    "                async with sess.get(url) as r2:\n",
    "                    if r2.status == 404 or r2.status == 429:\n",
    "                        return\n",
    "                    r2.raise_for_status()\n",
    "                    payload = await r2.json()\n",
    "            else:\n",
    "                r.raise_for_status()\n",
    "                payload = await r.json()\n",
    "\n",
    "    if isinstance(payload, dict) and payload.get(\"data\") == []:\n",
    "        log.write_text((log.read_text() + dest.stem + \"\\n\") if log.exists()\n",
    "                       else dest.stem + \"\\n\")\n",
    "        return\n",
    "\n",
    "    with gzip.open(dest, \"wt\") as fh:\n",
    "        json.dump(payload, fh)\n",
    "\n",
    "\n",
    "async def _all_tasks():\n",
    "    day = START_DATE\n",
    "    while day <= END_DATE:\n",
    "        ph = _ph(day)\n",
    "        for code, tpl in ENDPOINTS.items():\n",
    "            sub   = BASE_DIR / code\n",
    "            sub.mkdir(exist_ok=True)\n",
    "            url   = f\"{BASE_URL}{tpl.format(**ph)}\"\n",
    "            dest  = sub / f\"{ph['date']}.json.gz\"\n",
    "            log   = sub / \"empty.log\"\n",
    "            yield url, dest, log\n",
    "        day += dt.timedelta(days=1)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    connector = aiohttp.TCPConnector(limit=CONCURRENCY, ttl_dns_cache=300)\n",
    "    async with aiohttp.ClientSession(connector=connector,\n",
    "                                     timeout=TIMEOUT) as sess:\n",
    "        tasks = []\n",
    "        async for url, dest, log in _all_tasks():\n",
    "            tasks.append(asyncio.create_task(_fetch(sess, url, dest, log)))\n",
    "        CHUNK = 10_000\n",
    "        for i in range(0, len(tasks), CHUNK):\n",
    "            await asyncio.gather(*tasks[i:i+CHUNK])\n",
    "            print(f\"✓ {min(i+CHUNK, len(tasks)):,} / {len(tasks):,} done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268857bb-1a4a-4d50-8ba9-6065ba07fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2,343 / 2,343 done\n",
      "✅  completed\n"
     ]
    }
   ],
   "source": [
    "# This cell actually runs the download – it can take a while (≈ 40–60 k requests).\n",
    "await main()\n",
    "print(\"✅  completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e451d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
